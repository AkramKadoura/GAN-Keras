{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cvae_particles.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z3yXQyu-gyR"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import imageio\n",
        "from skimage import img_as_ubyte, io\n",
        "import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Activation, LeakyReLU, concatenate, Embedding, Dense,Input,Reshape,Dropout,LeakyReLU,Flatten,BatchNormalization,Conv2D,Conv2DTranspose,Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "# from scipy.stats import norm\n",
        "tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WednHn5u-gyc"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyQfUeqki2Df"
      },
      "source": [
        "!unzip /content/mparticles.zip -d /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCR3ohB1THOK"
      },
      "source": [
        "!pip install split-folders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNg0BDMcSIMJ"
      },
      "source": [
        "import splitfolders  # or import split_folders\n",
        "\n",
        "# Split with a ratio.\n",
        "# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
        "splitfolders.ratio('/content/mparticles', output='/content/mparticles-split', seed=1337, ratio=(.7, .15, .15), group_prefix=None) # default values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thw5oW6G-gyh"
      },
      "source": [
        "categories = ['CS', 'MC', 'SS']\n",
        "# categories = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "# data_directory = '/data1/akadoura/Experiments/fashion-split/train/'\n",
        "data_directory = '/content/mparticles-split/train/'\n",
        "\n",
        "\n",
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "    for category in categories:\n",
        "        path = os.path.join(data_directory, category)\n",
        "        class_num = categories.index(category)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "                resized_array = cv2.resize(img_array, (48,48))\n",
        "                training_data.append([resized_array, class_num])\n",
        "            except Exception as e:\n",
        "                pass"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG5Wjt9Z-gyj"
      },
      "source": [
        "create_training_data()\n",
        "print(len(training_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtUyHGzg-gyl"
      },
      "source": [
        "import random\n",
        "random.shuffle(training_data)\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "for features, label in training_data:\n",
        "    x_train.append(features)\n",
        "    y_train.append(label)\n",
        "    \n",
        "\n",
        "x_train = np.array(x_train).reshape(-1, 48, 48, 1)\n",
        "x_train = x_train/255\n",
        "# x_train = x_train * 2. - 1.\n",
        "# x_train = x_train.reshape(x_train.shape[0], -1)\n",
        "\n",
        "y_train = np.array(y_train).reshape(-1)\n",
        "y_train = to_categorical(y_train)\n",
        "# x_train = x_train.reshape(-1, 48, 48, 1) * 2. - 1."
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr1aAM_M-gyo"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhaTzc4v-gyr"
      },
      "source": [
        "batch_size = 50\n",
        "latent_dim = 32"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljzzmeYy-gyt"
      },
      "source": [
        "def sampling(args):\n",
        "    mu, log_var = args\n",
        "    eps = K.random_normal(shape=(batch_size, latent_dim), mean=0., stddev=1.0)\n",
        "    return mu + K.exp(log_var/2.) * eps"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17SVhcQ7-gyw"
      },
      "source": [
        "x = Input(shape=(48,48,1))\n",
        "condition = Input(shape=(y_train.shape[1],))\n",
        "\n",
        "upsample = Dense(48*48*1)(condition)\n",
        "upsample = Reshape((48,48,1))(upsample)\n",
        "\n",
        "inputs = concatenate([x, upsample])\n",
        "\n",
        "cx = Conv2D(filters=64, kernel_size=(3,3), strides=2, padding='same')(inputs)\n",
        "cx = LeakyReLU(0.2)(cx)\n",
        "cx = Dropout(0.4)(cx)\n",
        "\n",
        "cx = Conv2D(filters=64, kernel_size=(3,3), padding='same')(cx)\n",
        "cx = LeakyReLU(0.2)(cx)\n",
        "cx = Dropout(0.4)(cx)\n",
        "\n",
        "cx = Conv2D(filters=128, kernel_size=(3,3), strides=2, padding='same')(cx)\n",
        "cx = LeakyReLU(alpha=0.2)(cx)\n",
        "cx = Dropout(0.4)(cx)\n",
        "\n",
        "cx = Conv2D(filters=128, kernel_size=(3,3), padding='same')(cx)\n",
        "cx = LeakyReLU(alpha=0.2)(cx)\n",
        "cx = Dropout(0.4)(cx)\n",
        "\n",
        "cx = Conv2D(filters=256, kernel_size=(3,3), strides=2, padding='same')(cx)\n",
        "cx = LeakyReLU(alpha=0.2)(cx)\n",
        "cx = Dropout(0.4)(cx)\n",
        "\n",
        "f = Flatten()(cx)\n",
        "x_encoded = Dense(256)(f)\n",
        "x_encoded = LeakyReLU(alpha=0.2)(x_encoded)\n",
        "\n",
        "mu = Dense(latent_dim, activation='linear')(x_encoded)\n",
        "log_var = Dense(latent_dim, activation='linear')(x_encoded)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEuc3fuf-gyy"
      },
      "source": [
        "z = Lambda(sampling, output_shape=(latent_dim,))([mu, log_var])\n",
        "z_cond = concatenate([z, condition])\n",
        "                      \n",
        "encoder = Model([x, condition], z_cond)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPyCBmzsuUAn"
      },
      "source": [
        "encoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e1p5U_3-gy2"
      },
      "source": [
        "di = Input(shape=(z_cond.shape[1],))\n",
        "\n",
        "gen = Dense(6*6*256)(di)\n",
        "gen = LeakyReLU(alpha=0.2)(gen)\n",
        "gen = Reshape((6,6, 256))(gen)\n",
        "\n",
        "dx = Conv2DTranspose(filters=256, kernel_size=(4,4), strides=2, padding='same')(gen)\n",
        "dx = BatchNormalization(momentum=0.8)(dx)\n",
        "dx = LeakyReLU(alpha=0.2)(dx)\n",
        "\n",
        "dx = Conv2D(filters=128, kernel_size=(4,4), padding='same')(dx)\n",
        "dx = BatchNormalization(momentum=0.8)(dx)\n",
        "dx = LeakyReLU(alpha=0.2)(dx)\n",
        "\n",
        "dx = Conv2DTranspose(filters=128, kernel_size=(4,4), strides=2, padding='same')(dx)\n",
        "dx = BatchNormalization(momentum=0.8)(dx)\n",
        "dx = LeakyReLU(alpha=0.2)(dx)\n",
        "\n",
        "dx = Conv2D(filters=64, kernel_size=(4,4), padding='same')(dx)\n",
        "dx = BatchNormalization(momentum=0.8)(dx)\n",
        "dx = LeakyReLU(alpha=0.2)(dx)\n",
        "\n",
        "dx = Conv2DTranspose(filters=64, kernel_size=(4,4), strides=2, padding='same')(dx)\n",
        "dx = BatchNormalization(momentum=0.8)(dx)\n",
        "dx = LeakyReLU(alpha=0.2)(dx)\n",
        "\n",
        "y = Conv2D(filters=1, kernel_size=(7,7), padding='same', activation='sigmoid')(dx)\n",
        "\n",
        "decoder = Model(di, y)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X05xwTx7R9Bo"
      },
      "source": [
        "decoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICBb2n4Z-gy4"
      },
      "source": [
        "def vae_loss(true, pred):\n",
        "    reconstruction_loss = keras.losses.binary_crossentropy(K.flatten(true), K.flatten(pred)) * 48 * 48\n",
        "    kl_loss = 1 + log_var - K.square(mu) - K.exp(log_var)\n",
        "    kl_loss = K.sum(kl_loss, axis=-1)\n",
        "    kl_loss *= -0.5\n",
        "    return K.mean(reconstruction_loss + kl_loss)\n",
        "\n",
        "    \n",
        "cvae_outputs = decoder(encoder([x,condition]))\n",
        "cvae = Model([x, condition], cvae_outputs, name='cvae')\n",
        "\n",
        "cvae.compile(optimizer='adam', loss=vae_loss)\n",
        "\n",
        "cvae.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0jm_QXI-gy7"
      },
      "source": [
        "history = cvae.fit([x_train, y_train], x_train,\n",
        "       epochs=10,\n",
        "       batch_size=50, verbose=1)\n",
        "\n",
        "decoder.save('/content/decoder-particles.h5')\n",
        "encoder.save('/content/encoder-particles.h5')\n",
        "cvae.save('/content/cvae-particles.h5')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQt22o45-gy-"
      },
      "source": [
        "latent_space = encoder.predict([x_train, y_train], batch_size=batch_size)\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(latent_space[:, 0], latent_space[:, 1], c=np.argmax(y_train, axis=1))\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp5l-xgo-gzD"
      },
      "source": [
        "labels = to_categorical(1, 3).reshape(1,-1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEyaTFH4-gzF"
      },
      "source": [
        "for i in range(10):\n",
        "    plt.figure(figsize=(6, 1))\n",
        "    z_sample = np.random.normal(0, 1, 32).reshape(1,-1)\n",
        "    x_decoded = decoder.predict(np.column_stack([z_sample, labels]))\n",
        "    x_decoded = x_decoded * 255\n",
        "    image = x_decoded[0].reshape(48, 48)\n",
        "    # plt.imshow(image, cmap='gray',)\n",
        "    # plt.show()\n",
        "    img_name = f'generated-cvae-{i}.png'\n",
        "    imageio.imwrite('/content/imgs/'+img_name, image)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}