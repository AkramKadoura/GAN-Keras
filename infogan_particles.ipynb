{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "infogan_particles.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "24yPtLWvYGb-"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Conv2D,Conv2DTranspose, concatenate\n",
        "from keras.layers import LeakyReLU, Dropout, Embedding, Concatenate, BatchNormalization, ReLU, Activation\n",
        "from keras.utils import plot_model\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.utils import to_categorical\n",
        "from PIL import Image\n",
        "import imageio\n",
        "from skimage import img_as_ubyte, io\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "%matplotlib inline "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sszQj8DYGcH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02d8fa76-bff5-4f56-8cf2-a0d72c461453"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 27.4 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8BntXuRmqfV"
      },
      "source": [
        "!unzip -uq \"/content/mparticles.zip\" -d \"/content/\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GETvIIJcYGcK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7506188b-dfc0-4563-d2a1-3f06a793bb92"
      },
      "source": [
        "!pip install split-folders"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/5f/3c2b2f7ea5e047c8cdc3bb00ae582c5438fcdbbedcc23b3cc1c2c7aae642/split_folders-0.4.3-py3-none-any.whl\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8KYKx6FKqs5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d15b698-d198-4ffb-e071-099cd9d0f632"
      },
      "source": [
        "import splitfolders  # or import split_folders\n",
        "\n",
        "# Split with a ratio.\n",
        "# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
        "splitfolders.ratio(\"/content/mparticles\", output=\"/content/mparticles-split\", seed=1337, ratio=(.7, .15, .15), group_prefix=None) # default values"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying files: 3707 files [00:00, 9818.97 files/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3-fS5Z8YGcP"
      },
      "source": [
        "categories = ['CS', 'MC', 'SS']\n",
        "data_directory = '/content/mparticles-split/train/'\n",
        "\n",
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "    for category in categories:\n",
        "        path = os.path.join(data_directory, category)\n",
        "        class_num = categories.index(category)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "                resized_array = cv2.resize(img_array, (48,48))\n",
        "                training_data.append([resized_array, class_num])\n",
        "            except Exception as e:\n",
        "                pass"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytZkz7a5YGcR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89ac3aff-7cec-4eba-f789-4ffe330adcbb"
      },
      "source": [
        "create_training_data()\n",
        "print(len(training_data))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASE-hh4OYGcT"
      },
      "source": [
        "import random\n",
        "random.shuffle(training_data)\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "for features, label in training_data:\n",
        "    x_train.append(features)\n",
        "    y_train.append(label)\n",
        "    \n",
        "    \n",
        "x_train = np.array(x_train).reshape(-1, 48, 48, 1)\n",
        "y_train = np.array(y_train).reshape(-1)\n",
        "\n",
        "x_train = x_train/255\n",
        "x_train = x_train.reshape(-1, 48, 48, 1) * 2. - 1.\n",
        "\n",
        "#y_train = tensorflow.keras.utils.to_categorical(y_train)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybE42nflYGcW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "c9fe29c7-abb7-48f8-c4b9-39a2a12a91e1"
      },
      "source": [
        "print(y_train[30])\n",
        "plt.figure(figsize = (8,1))\n",
        "plt.imshow(x_train[30].reshape(48,48), cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFgAAABZCAYAAAC6yeORAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANOUlEQVR4nO1cTag0RxU91TPdb+bNvPciuPnQoEHcRxBdZC2IG3UjRtCFi7gJKLgRV4Jbo8tAgtkJbnQhEhAXbtxIYghqEpQggglBCEh889PTPd3l4s2p7/R91TPz5vf5OReK6en/Pn3r1Lm3qtp573Gy/Vly7Bt41O0E8J7tBPCe7QTwnu0E8J7tBPCebSuAnXOfd8791Tn3tnPue7u6qUfJ3KY62DnXAfA3AJ8D8A6AVwA87b1/c3e3979v23jwZwC87b3/u/e+APBzAF/czW09Otbd4tiPAPin/H8HwGeXHdDpdHyapgAA51z4dc4hSZLw2+l0kCRJWNfpdMJ+LHoOrYXe+0ap63rtwvPcpVY753i8i23fBuB1b+AZAM8AQLfbxRNPPAEud7tdZFmGXq+H8/NzXF5eYjAYYDgc4vz8HP1+H+fn5+j1euj1euGYTqcTXgItSRIURYGqqlCWJYqiQFEUmM1myPMc19fXmEwmmE6nGI/HGI1GGI1GuL6+xgcffIDpdIr5fI6yLFFVVQBcX6L3vnFNbhuNRq3Pvw3A7wJ4XP5/dLGuYd77FwC8AAD9ft/TG7vdbgCu3+/j4uICV1dXGA6HGA6H6Pf7oSjAnU4H3W43gAoAdV0jTVOUZRlAIshnZ2fo9XrodDrIsgxpmiJNU3S73XB8VVXw3iPP8wCurR11XTf+2+U22wbgVwB80jn3BG6A/SqAr606iADRcweDAQaDAS4vL3F1dYWLi4vgtfqbZVnDe0kV9LQ0TVEUBebzeSgEeTabhWvz+kpLdV1jPp+jqqoAthYaKYfgc90y2xhg7/3cOfcsgN8A6AB4yXv/xrJj+FDdbhdnZ2eBAgaDAS4uLnBxcdGgB3ouAe50OkjTNPAzgMCfBL+qqgAuPVUBtaWuaxRFgTzPQw2oqqrB9zGv5Xr7EnYG8OJiLwN4+S7HdLtdpGna4N7hcIjBYBCAVe49OzsLRTmY4ABoAEzv7XQ6KMsyNJoWBHrjfD7HbDbDZDJBnueYzWYBZHJuVVW3jl23Idx7I6dGRZCmaeBG9WTyca/Xu8WXLGmaBooAHnoUAVfvVIVCkOjhBLEsy8Y1eR0CzJfI+9drWrqI2UEBBnBLOQwGgwCwgkyvzbIM/X4/0Aobp1jrTpAJYpZlgZeTJEGWZcGjsywL53fOBb6ez+cBWAXYXm/t5909hO3mnAvAsgyHQ1xeXgb+JbjkXwJOWqGCsA+aJAnm83kAhjycZVkDYILLc1OXKw9T4qmpZIvp7zY7uAcrPagU04aN1KBa12peoNng6HbSgQLQ7XYD0CxUFCrhlIqoiduM11xGE0flYBbLs6QB5VIF03IwlzUatMvKpRrhkYOpZMbjMabTKYqiCKrCHm+faZkdHGD1FC5rg0atqtFaW4npUepa++BpmoYggoU8rbKRDa+NGO/KvbSDA2w9N8uyUKwna15CH5bqgPoWQNCuvA6AIM/YCJIS7DWUFiyw9kXF5N7edPBdLUmShra1oJI+rCTTCEz5U2UYcMOz3nuUZXlLASiXx2rBqhDYOdeI8tZ+5o3R2sCSJGnkFwiyemub93C7zSPEwtdYg6gvRc8dk1/e+0AnbORUtmnmbZUd1IM7nQ6urq7w2GOPhdCYOphefX5+Hq2a4YYX4LY94KoHtyBp0ED9bIOMGKA89l41cjQqAU1Z2mSO7ssGKU3TEAZzH036xK4h+dqoRNMGV9sCW4tWAdlmB2/kqBYo9q0WZmSlHqRpxfl8fitxQ35UhQCgcY5Y8j2WKYu9qGU1ZpUdJVTWoiErPZim+tY2SORdeibBUe5UILm/emKbV94FzDZ9HJ537TPtwJIkaXiwTeZYGUZjdbcBRl3XQYpZTWwbLZ7H7qcBh60FtutpEzuaDlbetfLLgqyUwP9t56c3t8kv9Whm1Ri1zWaz0O2k++mLuitVHCXZQ4mmkkvBjMk0lVdtPQrkSuvl6o2qFrR7aTabhVKW5S164fm0NqxjR8lF2OoONIFa5rHayxBrmFRiWTBj/EyQtauJx9jeC3svsf/WDt7I2Zbebov91340rbYKsg08tFoTOAV+Pp+HHgz+TqfT8IL0+jF+5/a99cltYpo/UM8qiiLwL2UY0JRnzANr2Kteql7JZfXCuq6R5znyPA/5Xl6b99Em4docgpS0rAE8KMDME8xmM6Rpitls1sjHxrSsgqnLMZWglGApoKqqwLHT6RTT6TR4rnJuWzTH81tbRRErcxHOucedc79zzr3pnHvDOfftxfofOOfedc69vihfWA0xgrfZQR4x6iDfkq9joALN3IPNJ+i1lGdjvKwvx1KNPf+6to4HzwF813v/mnPuAsAfnXO/XWz7iff+R+teTB+aD8ZWnCEwH1YbOQugcm+bUlAP1kbLvlAbkMQ4fhtbCbD3/j0A7y2Wr51zb+FmXNpGZqtuURSNsQs2yU7QtUNTz2VBU3rQl2m9X4uec9OcQ5vdiYOdcx8H8CkAfwDwFIBnnXPfAPAqbrz835Fjwti0q6ur0LBYmWbzC7HwmODxvwKkgYMuWz5dxzu1xmxrawPsnBsC+AWA73jv/+Ocex7ADwH4xe9zAL5pj/MyNu3BgweeHrvY1qiuVv/WdY2zs7OGB1vv4358cdpIWe7VF2F53wYW60iwdWwtgJ1zKW7A/Zn3/pcLcP4l218E8OtV51FNSkmWJElQE3me3xpYYnuQdVm9l+GuBZQ0VFVVkGfaNa+jMPlrX4DeR+yZltlKgN3Nk/4UwFve+x/L+gcLfgaALwP4y6pzaQ7A9lyMx2MACOAMBoMAmHYX0az+ZTeR9V4tSiGqw7VYKlLTWsTn2UWg8RSArwP4s3Pu9cW67wN42jn3JG4o4h8AvrXGuQJgWtI0hfc+BByz2azRYcnBIerNKqsA3JJZscBBwdeITY+PjYOIjU3j79YAe+9/DyDWtN5p0B9vSAFWpaCxPiMketXZ2dnNzS6421Zf65E2ENH8hWbKADQa0mX3bXMlsTxFzI4SyVmAY8kU1agMsYGH4WmMh5cpBj2n9d4YwDGl4X28D+7eAmynAQC3H5Zjytgg6stQT1ymDmyEZl9AW8S2igJWeS9wBICpgWOdiprz1eSPAkcPVl7U89jggstM6ijgVBMM2S3FxBo6WyPuVbqyrmtMJhMAaHgSgFuyjCB3u90AhPV27x9OSmFjSQAtuDYs1miSKUt9kQoir6XXjeVEYnZwD9aeBA2FabEqrjJKozzdn2bTmeqRXKemQNvIT/dpO36VHRTgqqowGo0wn8/R6/UacyKoFjimV6s6A4bBYBA6TBVk1oRYZozg2RcB3OZ7Sj49px6zCcgHp4jpdAqgOUYs1gen6oCmQp/9eTqwhMdZ2VYURag9GnRof5wNRGxAob/3WqYxHCZFxJI8arbhU1MdTIWiPRT0fA0+dHJinueYTqchEW+jw1hiyMrJewcwPUZ7iHWkuQXddimpTlbZRoUSC4+pErRBm06nmEwmYXYRu5IU4JgOjj3TMjs4RTAMbgOYv9ym+9hQWcdBkAJ0ZDpBppJQzyXICi73bdPAsbEWq+xoOpgA69hfDu5jp6gm2G0XvnqwqgXrvRZczZrpOlUPMQA3ARc4AsBKDzTVvASXszaZh7BSiRxOD7a8axXKZDJp9XCGwBqG23wH7/9eAwzcTJdqy/USLI5ZU7nF36IoGiPfebyGwwou15NzZ7MZxuMxxuMxrq+vMRqNwsQXnU4bk2eb2FFkmsooal96lI5+J5BZliHP8zCmLTa9y3qxAs6uevIuP2nAYqM4m+Zc1tDdq1AZeDigmlWZ68jHwEOP5PDWqqqCR5dl2Ui+M9WpiXfuR9DptQowPdoOPLG53m28FzgCwJqosRyXJEnwPA5vLYqiMdTVDhjUscE2rGatyPO8IcdYNMBo07/b2lHGptnQVr2FjZACynlrOitJAxB9YRZgTpHl5EL+V80cG3a1C3CBIwBMMEgLFvAsyxrfeuCEbn4hRfvndDAggAb1qJooyzJEbDb4aHvRbQn5e60iGAwAiMoibrcTVPg5Ge11VoBt1bbKo67rW3rXUoImetTWDYnb7CgUocsaifE/0JwXN5lMkGUZAIQoT8eraYCgVZ21RRs929NhezZi9LDNaJ9De/D7ZVmOAbx/wMt+eJvrrfLaxfaPtW3f+Mt/m5pz7lXv/acf1etZO30cdM92AnjPdgyAX3jEr9ewg3Pw/5udKGLPdjCA3Z4/5rzruSQ7u69DUIQ7wMecnXMPADzwMpcEwJcAfAXAyN9hLsku7VAevPePOXvv3/Pev7ZYvgaw1VySXdmhAI59zHlvD2/mkgA3c0n+5Jx7yTn3oX1dN2aPXCNn55IAeB7AJwA8iZvZUs8d8n4OBfBaH3Pe1trmknjvK+99DeBF3NDVwexQAIePOTvnMtx8zPlXu7zAsrkksttac0l2aQfJpvkNPua8ge10Lsmu7BTJ7dkeuUbuvtkJ4D3bCeA92wngPdsJ4D3bCeA92wngPdsJ4D3bfwFzjdqpBfhEZAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2CxjcShYGcY"
      },
      "source": [
        "input_shape = (48,48,1)\n",
        "classes = 3\n",
        "latent_dim = 100\n",
        "latent_code = 4\n",
        "concatenated_input = latent_dim + latent_code\n",
        "\n",
        "def build_discriminator():\n",
        "    init = RandomNormal(mean=0.0, stddev=0.02)\n",
        "\n",
        "    input_label = Input(shape=(1,)) \n",
        "    emb = Embedding(classes,40)(input_label)\n",
        "    upsample = Dense(48*48*1)(emb)\n",
        "    upsample = Reshape((48,48,1))(upsample)\n",
        "    \n",
        "    input_image = Input(shape=(48,48,1))\n",
        "\n",
        "    concat = Concatenate()([input_image, upsample])\n",
        "\n",
        "    h = Conv2D(64, kernel_size = (3,3), strides=2, padding='same', kernel_initializer=init)(concat)\n",
        "    h = LeakyReLU(alpha=0.2)(h)\n",
        "    h = Dropout(0.4)(h)\n",
        "\n",
        "    h = Conv2D(64, kernel_size = (3,3), padding='same', kernel_initializer=init)(h)\n",
        "    h = LeakyReLU(alpha=0.2)(h)\n",
        "    h = Dropout(0.4)(h)\n",
        "    \n",
        "    h0 = Conv2D(128, kernel_size = (3,3), strides=2, padding='same', kernel_initializer=init)(h)\n",
        "    h0 = LeakyReLU(alpha=0.2)(h0)\n",
        "    h0 = Dropout(0.4)(h0)\n",
        "    \n",
        "    h1 = Conv2D(128, kernel_size = (3,3), padding='same', kernel_initializer=init)(h0)\n",
        "    h1 = LeakyReLU(alpha=0.2)(h1)\n",
        "    h1 = Dropout(0.4)(h1)\n",
        "    \n",
        "    h2 = Conv2D(256, kernel_size = (3,3), strides=2, padding='same', kernel_initializer=init)(h1)\n",
        "    h2 = LeakyReLU(alpha=0.2)(h2)\n",
        "    h2 = Dropout(0.4)(h2)\n",
        "    \n",
        "    flat = Flatten()(h2)\n",
        "    output = Dense(1, activation='sigmoid')(flat)\n",
        "    \n",
        "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "    discriminator = Model(inputs=[input_image, input_label], outputs=output)\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])    \n",
        "\n",
        "    aux = Dense(128)(flat)\n",
        "    aux = LeakyReLU(alpha=0.2)(aux)\n",
        "    output2 = Dense(latent_code, activation='softmax')(aux)\n",
        "   \n",
        "    auxiliary = Model(inputs=[input_image, input_label], outputs=output2)\n",
        "   \n",
        "    return discriminator, auxiliary"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-81fFIXYGca"
      },
      "source": [
        "def build_generator():\n",
        "    init = RandomNormal(mean=0.0, stddev=0.02)\n",
        "    \n",
        "    input_label = Input(shape=(1,))\n",
        "    emb = Embedding(classes, 40)(input_label)\n",
        "    emb = Dense(6*6*1)(emb)\n",
        "    emb = Reshape((6, 6, 1))(emb)\n",
        "\n",
        "    input_latent = Input(shape=(concatenated_input,))\n",
        "    gen = Dense(256 * 6 * 6 )(input_latent)\n",
        "    gen = LeakyReLU(alpha=0.2)(gen)\n",
        "    gen = Reshape((6,6, 256))(gen)\n",
        "\n",
        "    merge = Concatenate()([gen, emb])\n",
        "\n",
        "    gen = Conv2D(256, (4,4), padding='same', kernel_initializer=init)(merge)\n",
        "    gen = BatchNormalization(momentum=0.8)(gen)\n",
        "    gen = LeakyReLU(alpha=0.2)(gen)\n",
        "\n",
        "    gen = Conv2DTranspose(256, (4,4), strides=(2,2), padding='same', kernel_initializer = init)(gen)\n",
        "    gen = BatchNormalization(momentum=0.8)(gen)\n",
        "    gen = LeakyReLU(alpha=0.2)(gen)\n",
        "    \n",
        "    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer = init)(gen)\n",
        "    gen = BatchNormalization(momentum=0.8)(gen)\n",
        "    gen = LeakyReLU(alpha=0.2)(gen)\n",
        "    \n",
        "    out_layer = Conv2DTranspose(1, (4,4), strides=(2,2), padding='same', activation='tanh', kernel_initializer = init)(gen)\n",
        "    \n",
        "    model = Model([input_latent, input_label], out_layer)\n",
        "    return model"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PyZWGr2YGcc"
      },
      "source": [
        "def build_gan(generator, discriminator, auxiliary):\n",
        "    discriminator.trainable = False\n",
        "    generator_latent, generator_label = generator.input\n",
        "    discriminator_output = discriminator([generator.output, generator_label])\n",
        "    auxiliary_output = auxiliary([generator.output, generator_label])\n",
        "\n",
        "    gan = Model([generator_latent, generator_label], [discriminator_output, auxiliary_output])\n",
        "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "    gan.compile(loss=['binary_crossentropy', 'categorical_crossentropy'], optimizer=opt)\n",
        "    return gan"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXuHiJS6YGcl"
      },
      "source": [
        "def plot_loss_history(d1, d2, g):\n",
        "    fig = plt.figure(figsize=(10,6))\n",
        "    # plt.style.use('seaborn-whitegrid')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.plot(d1, 'r', label='d_loss_real')\n",
        "    plt.plot(d2, 'c', label='d_loss_fake')\n",
        "    plt.plot(g, 'y', label='g_loss')\n",
        "    plt.legend(loc='lower left', bbox_to_anchor=(0.82, 0.8), fancybox=True, shadow=True, ncol=1)\n",
        "    plt.savefig('/content/infogan_logs/infogan_loss_history.png')\n",
        "    plt.close()\n",
        "    \n",
        "def plot_acc_history(a1, a2):\n",
        "    fig = plt.figure(figsize=(10,6))\n",
        "    # plt.style.use('seaborn-whitegrid')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.ylim(0, 100)\n",
        "    plt.plot(a1, 'r', label='acc_real')     \n",
        "    plt.plot(a2, 'c', label='acc_fake')\n",
        "    plt.legend(loc='lower left', bbox_to_anchor=(0.82, 0.04), fancybox=True, shadow=False, ncol=1)\n",
        "    plt.savefig('/content/infogan_logs/infogan_acc_history.png')\n",
        "    plt.close()\n",
        "    \n",
        "def plot_total_loss(d, g):\n",
        "    fig = plt.figure(figsize=(10,6))\n",
        "    # plt.style.use('seaborn-whitegrid')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.plot(d, 'r', label='d_loss')\n",
        "    plt.plot(g, 'y', label='g_loss')\n",
        "    plt.legend(loc='lower left', bbox_to_anchor=(0.82, 0.8), fancybox=True, shadow=True, ncol=1)\n",
        "    plt.savefig('/content/infogan_logs/infogan_total_loss.png')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_A_loss(d):\n",
        "    fig = plt.figure(figsize=(10,6))\n",
        "    # plt.style.use('seaborn-whitegrid')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.plot(d, 'r', label='Auxiliary_loss')\n",
        "    plt.legend(loc='lower left', bbox_to_anchor=(0.82, 0.8), fancybox=True, shadow=True, ncol=1)\n",
        "    plt.savefig('/content/infogan_logs/infogan_A_loss.png')\n",
        "    plt.close()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx4YIUefYGcp"
      },
      "source": [
        "discriminator, auxiliary = build_discriminator()\n",
        "generator = build_generator()\n",
        "gan = build_gan(generator, discriminator, auxiliary)\n",
        "\n",
        "auxiliary.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eFgLAmvYGcu"
      },
      "source": [
        "epochs=10000\n",
        "batch_size=64\n",
        "\n",
        "d = list()\n",
        "d1 = list()\n",
        "d2 = list()\n",
        "g  = list() \n",
        "a1 = list() \n",
        "a2 = list()\n",
        "da = list()\n",
        "ga = list()\n",
        "aux = list()\n",
        "\n",
        "def generate_latent_variables(latent_dim, samples, latent_code, classes=3):\n",
        "    x = np.random.randn(latent_dim * samples)\n",
        "    x = x.reshape(samples, latent_dim)\n",
        "    label = np.random.randint(0, classes, samples)\n",
        "    category = np.random.randint(0, latent_code, samples)\n",
        "    category = to_categorical(category, num_classes=latent_code)\n",
        "    z = np.hstack((x, category))\n",
        "    return [z, category, label]\n",
        " \n",
        "def fake_samples(generator, latent_dim, samples):\n",
        "    z, category, label = generate_latent_variables(latent_dim, samples, latent_code)\n",
        "    images = generator.predict([z, label])\n",
        "    y = np.zeros((samples, 1))\n",
        "    return [images, label], y\n",
        "\n",
        "def real_samples(x_train, samples):\n",
        "    random_samples = np.random.randint(0, x_train.shape[0], samples)\n",
        "    x, label = x_train[random_samples], y_train[random_samples]\n",
        "    y = np.ones((samples, 1))\n",
        "    return [x, label], y\n",
        "\n",
        "    \n",
        "for i in range(epochs):\n",
        "    for j in range(58):\n",
        "                \n",
        "        [x_real, real_labels], y_real = real_samples(x_train, batch_size//2)\n",
        "        d_loss_real, d_acc_real = discriminator.train_on_batch([x_real, real_labels], y_real)\n",
        "            \n",
        "        [x_fake, fake_labels], y_fake = fake_samples(generator, latent_dim, batch_size//2)\n",
        "        d_loss_fake, d_acc_fake = discriminator.train_on_batch([x_fake, fake_labels], y_fake)\n",
        "        \n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "        d_acc = 0.5 * np.add(d_acc_real, d_acc_fake)\n",
        "            \n",
        "        z, category, label = generate_latent_variables(latent_dim, batch_size, latent_code)\n",
        "        y_gan = np.ones((batch_size, 1))\n",
        "                    \n",
        "        g_0, g_1, g_2 = gan.train_on_batch([z, label], [y_gan, category])\n",
        "        \n",
        "    d.append(d_loss)\n",
        "    d1.append(d_loss_real)\n",
        "    d2.append(d_loss_fake)\n",
        "    g.append(g_1)\n",
        "    a1.append(d_acc_real*100)\n",
        "    a2.append(d_acc_fake*100)\n",
        "    da.append(d_acc*100)\n",
        "    aux.append(g_2)\n",
        "    \n",
        "    if (i%200 == 0):\n",
        "        generator.save(f'/content/infogan_logs/infogan-particles-{i}.h5')\n",
        "        plot_loss_history(d1, d2, g)\n",
        "        plot_acc_history(a1, a2)\n",
        "        plot_total_loss(d, g)\n",
        "        plot_A_loss(aux)\n",
        "            \n",
        "    print(f'Epoch: {i+1}:  D_loss_r: {d_loss_real} -  D_loss_f: {d_loss_fake} - G_loss: {g_1} - A_loss: {g_2}')\n",
        "    \n",
        "    \n",
        "plot_loss_history(d1, d2, g)\n",
        "plot_acc_history(a1, a2)\n",
        "plot_total_loss(d, g)\n",
        "plot_A_loss(aux)\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhKArNp-bDDf"
      },
      "source": [
        "def generate_latent_variables(latent_dim, samples, latent_code=4):\n",
        "    x = np.random.randn(latent_dim * samples)\n",
        "    x = x.reshape(samples, latent_dim)\n",
        "    labels = np.asarray([x for _ in range(10) for x in range(0,1)])\n",
        "    category = np.random.randint(0, latent_code, samples)\n",
        "    category = to_categorical(category, latent_code)\n",
        "    z = np.hstack((x, category))\n",
        "    return [z, category, labels]\n",
        "\n",
        "z_input, category, labels = generate_latent_variables(100, 10)\n",
        "images  = generator.predict([z_input, labels])\n",
        "images = (images+1)/2 * 255"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "VmPS8pDPYGc0"
      },
      "source": [
        "i=0\n",
        "for image in images:\n",
        "    plt.figure(figsize = (10,1))\n",
        "    i+=1\n",
        "    # plt.imshow(image.reshape(48,48), cmap='gray')\n",
        "    # plt.show()\n",
        "    img_name = f'generated-infogan-{i}.png'\n",
        "    imageio.imwrite('/content/imgs/'+img_name, image)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}